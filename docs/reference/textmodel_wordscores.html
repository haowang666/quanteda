<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Wordscores text model — textmodel_wordscores • quanteda</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">quanteda</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="http://github.com/kbenoit/quanteda">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Wordscores text model</h1>
    </div>

    
    <p><code>textmodel_wordscores</code> implements Laver, Benoit and Garry&#39;s (2003) 
wordscores method for scaling of a single dimension.</p>
    

    <pre><span class='fu'>textmodel_wordscores</span>(<span class='no'>data</span>, <span class='no'>scores</span>, <span class='kw'>scale</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"linear"</span>, <span class='st'>"logit"</span>), <span class='kw'>smooth</span> <span class='kw'>=</span> <span class='fl'>0</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <dl class="dl-horizontal">
      <dt>data</dt>
      <dd>the dfm on which the model will be fit.  Does not need to contain
only the training documents, since the index of these will be matched 
automatically.</dd>
      <dt>scores</dt>
      <dd>vector of training scores associated with each document 
identified in <code>refData</code></dd>
      <dt>scale</dt>
      <dd>classic LBG linear posterior weighted word class differences, or
logit scale of log posterior differences</dd>
      <dt>smooth</dt>
      <dd>a smoothing parameter for word counts; defaults to zero for the
to match the LBG (2003) method.</dd>
    </dl>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Fitting a <code>textmodel_wordscores</code> results in an object of class 
  <code>textmodel_wordscores_fitted</code> containing the following slots:</p>
    
    <h2 class="hasAnchor" id="slots"><a class="anchor" href="#slots"></a>Slots</h2>

    <p></p>
    <p><dl class='dl-horizontal'>
<dt><code>scale</code></dt><dd><code>linear</code> or <code>logit</code>, according to the value of 
<code>scale</code></dd></p>
    <p><dt><code>Sw</code></dt><dd>the scores computed for each word in the training set</dd></p>
    <p><dt><code>x</code></dt><dd>the dfm on which the wordscores model was called</dd></p>
    <p><dt><code>y</code></dt><dd>the reference scores</dd></p>
    <p><dt><code>call</code></dt><dd>the function call that fitted the model</dd></p>
    <p><dt><code>method</code></dt><dd>takes a value of <code>wordscores</code> for this model</dd>
</dl></p>
    
    <h2 class="hasAnchor" id="predict-methods"><a class="anchor" href="#predict-methods"></a>Predict Methods</h2>

    <p>A <code>predict</code> method is also available for a 
  fitted wordscores object, see 
  <code><a href='textmodel-internal.html'>predict.textmodel_wordscores_fitted</a></code>.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Laver, Michael, Kenneth R Benoit, and John Garry. 2003. 
  &quot;Extracting Policy Positions From Political Texts Using Words as Data.&quot; 
  American Political Science Review 97(02): 311-31</p>
    <p>Beauchamp, N. 2012. &quot;Using Text to Scale Legislatures with Uninformative 
  Voting.&quot; New York University Mimeo.</p>
    <p>Martin, L W, and G Vanberg. 2007. &quot;A Robust Transformation Procedure for 
  Interpreting Political Text.&quot; Political Analysis 16(1): 93-100.</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <p><code><a href='textmodel-internal.html'>predict.textmodel_wordscores_fitted</a></code></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'>(<span class='no'>ws</span> <span class='kw'>&lt;-</span> <span class='fu'>textmodel_wordscores</span>(<span class='no'>data_dfm_LBGexample</span>, <span class='fu'>c</span>(<span class='fu'>seq</span>(-<span class='fl'>1.5</span>, <span class='fl'>1.5</span>, <span class='fl'>.75</span>), <span class='fl'>NA</span>)))</div><div class='output co'>#&gt; Fitted wordscores model:
#&gt; Call:
#&gt; 	textmodel_wordscores(data = data_dfm_LBGexample, scores = c(seq(-1.5, 
#&gt;     1.5, 0.75), NA))
#&gt; 
#&gt; Reference documents and reference scores:
#&gt; 
#&gt;  Documents Ref scores
#&gt;         R1      -1.50
#&gt;         R2      -0.75
#&gt;         R3       0.00
#&gt;         R4       0.75
#&gt;         R5       1.50
#&gt;         V1          .
#&gt; 
#&gt; Word scores: showing first 30 scored features
#&gt; 
#&gt;     A     B     C     D     E     F     G     H     I     J     K     L     M 
#&gt; -1.50 -1.50 -1.50 -1.50 -1.50 -1.48 -1.48 -1.45 -1.41 -1.32 -1.18 -1.04 -0.88 
#&gt;     N     O     P     Q     R     S     T     U     V     W     X     Y     Z 
#&gt; -0.75 -0.62 -0.45 -0.30 -0.13  0.00  0.13  0.30  0.45  0.62  0.75  0.88  1.04 
#&gt;    ZA    ZB    ZC    ZD 
#&gt;  1.18  1.32  1.41  1.45 </div><div class='input'>
<span class='fu'>predict</span>(<span class='no'>ws</span>)</div><div class='output co'>#&gt; Predicted textmodel of type: wordscores
#&gt; 
#&gt;    textscore LBG se   ci lo   ci hi
#&gt; R1   -1.3179 0.0067 -1.3311 -1.3048
#&gt; R2   -0.7396 0.0114 -0.7620 -0.7172
#&gt; R3    0.0000 0.0120 -0.0235  0.0235
#&gt; R4    0.7396 0.0114  0.7172  0.7620
#&gt; R5    1.3179 0.0067  1.3048  1.3311
#&gt; V1   -0.4481 0.0119 -0.4714 -0.4247
#&gt; </div><div class='input'><span class='fu'>predict</span>(<span class='no'>ws</span>, <span class='kw'>rescaling</span> <span class='kw'>=</span> <span class='st'>"mv"</span>)</div><div class='output co'>#&gt; <span class='warning'>Warning: </span>
#&gt; <span class='warning'>More than two reference scores found with MV rescaling; using only min, max values.</span></div><div class='output co'>#&gt; Predicted textmodel of type: wordscores
#&gt; 
#&gt;    textscore LBG se   ci lo   ci hi MV rescaled
#&gt; R1   -1.3179 0.0067 -1.3311 -1.3048     -1.5000
#&gt; R2   -0.7396 0.0114 -0.7620 -0.7172     -0.8417
#&gt; R3    0.0000 0.0120 -0.0235  0.0235      0.0000
#&gt; R4    0.7396 0.0114  0.7172  0.7620      0.8417
#&gt; R5    1.3179 0.0067  1.3048  1.3311      1.5000
#&gt; V1   -0.4481 0.0119 -0.4714 -0.4247     -0.5100
#&gt; </div><div class='input'><span class='fu'>predict</span>(<span class='no'>ws</span>, <span class='kw'>rescaling</span> <span class='kw'>=</span> <span class='st'>"lbg"</span>)</div><div class='output co'>#&gt; Predicted textmodel of type: wordscores
#&gt; 
#&gt;    textscore LBG se   ci lo   ci hi LBG rescaled  LBG lo  LBG hi
#&gt; R1   -1.3179 0.0067 -1.3311 -1.3048      -1.5897 -1.6057 -1.5737
#&gt; R2   -0.7396 0.0114 -0.7620 -0.7172      -0.8849 -0.9122 -0.8576
#&gt; R3    0.0000 0.0120 -0.0235  0.0235       0.0163 -0.0124  0.0450
#&gt; R4    0.7396 0.0114  0.7172  0.7620       0.9175  0.8902  0.9448
#&gt; R5    1.3179 0.0067  1.3048  1.3311       1.6223  1.6063  1.6383
#&gt; V1   -0.4481 0.0119 -0.4714 -0.4247      -0.5297 -0.5581 -0.5013
#&gt; </div><div class='input'>
<span class='co'># same as:</span>
(<span class='no'>ws2</span> <span class='kw'>&lt;-</span> <span class='fu'>textmodel_wordscores</span>(<span class='no'>data_dfm_LBGexample</span>, <span class='fu'>c</span>(<span class='fu'>seq</span>(-<span class='fl'>1.5</span>, <span class='fl'>1.5</span>, <span class='fl'>.75</span>), <span class='fl'>NA</span>)))</div><div class='output co'>#&gt; Fitted wordscores model:
#&gt; Call:
#&gt; 	textmodel_wordscores(data = data_dfm_LBGexample, scores = c(seq(-1.5, 
#&gt;     1.5, 0.75), NA))
#&gt; 
#&gt; Reference documents and reference scores:
#&gt; 
#&gt;  Documents Ref scores
#&gt;         R1      -1.50
#&gt;         R2      -0.75
#&gt;         R3       0.00
#&gt;         R4       0.75
#&gt;         R5       1.50
#&gt;         V1          .
#&gt; 
#&gt; Word scores: showing first 30 scored features
#&gt; 
#&gt;     A     B     C     D     E     F     G     H     I     J     K     L     M 
#&gt; -1.50 -1.50 -1.50 -1.50 -1.50 -1.48 -1.48 -1.45 -1.41 -1.32 -1.18 -1.04 -0.88 
#&gt;     N     O     P     Q     R     S     T     U     V     W     X     Y     Z 
#&gt; -0.75 -0.62 -0.45 -0.30 -0.13  0.00  0.13  0.30  0.45  0.62  0.75  0.88  1.04 
#&gt;    ZA    ZB    ZC    ZD 
#&gt;  1.18  1.32  1.41  1.45 </div><div class='input'><span class='fu'>predict</span>(<span class='no'>ws2</span>)</div><div class='output co'>#&gt; Predicted textmodel of type: wordscores
#&gt; 
#&gt;    textscore LBG se   ci lo   ci hi
#&gt; R1   -1.3179 0.0067 -1.3311 -1.3048
#&gt; R2   -0.7396 0.0114 -0.7620 -0.7172
#&gt; R3    0.0000 0.0120 -0.0235  0.0235
#&gt; R4    0.7396 0.0114  0.7172  0.7620
#&gt; R5    1.3179 0.0067  1.3048  1.3311
#&gt; V1   -0.4481 0.0119 -0.4714 -0.4247
#&gt; </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#details">Details</a></li>

      <li><a href="#slots">Slots</a></li>

      <li><a href="#predict-methods">Predict Methods</a></li>

      <li><a href="#references">References</a></li>

      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    
Kenneth Benoit

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Kenneth Benoit.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
