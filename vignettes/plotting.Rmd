---
title: "Plotting with quanteda"
output: 
  rmarkdown::html_vignette:
    css: mystyle.css
    toc: yes
vignette: >
  %\VignetteIndexEntry{Plotting}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r eval=TRUE}
library(quanteda)
```

At the moment, two quanteda objects, `dfm` and `kwic` have custom plot methods: `dfm` is plotted as a wordcloud, `kwic` as a lexical dispersion plot. There are also other plots of interest which can be made with the standard R techniques.

# 1. Wordcloud 

Plotting a `dfm` object will create a wordcloud using the `wordcloud` pacakge.

```{r eval=TRUE, fig.width=8, fig.height=8}
# Create a dfm from a somewhat smaller corpus
inaugDfm <- dfm(data_corpus_inaugural[0:10], remove = stopwords('english'), removePunct = TRUE)
# Some words will not fit on a plot this size, so suppress those warings
textplot_wordcloud(dfm_trim(inaugDfm, min_count = 10, verbose = FALSE))
```

You can also plot a "comparison cloud", but this can only be done with fewer than eight documents:

```{r eval=TRUE, fig.width=8, fig.height=8}
compDfm <- dfm(corpus_subset(data_corpus_inaugural, President %in% c("Washington", "Jefferson", "Madison")),
               groups = "President", remove = stopwords("english"), removePunct = TRUE)
textplot_wordcloud(dfm_trim(compDfm, min_count = 5, verbose = FALSE), comparison = TRUE)
```

Plot will pass through additional arguments to the underlying call to `wordcloud`.
```{r eval=TRUE, fig.width=8, fig.height=8}
textplot_wordcloud(inaugDfm, min.freq = 10,
     colors = c('red', 'pink', 'green', 'purple', 'orange', 'blue'))
```

# 2. Lexical dispersion plot

Plotting a `kwic` object produces a lexical dispersion plot which allows us to visualize the occurrences of particular terms throughout the text.  We call these "x-ray" plots due to their similarity to the data produced by [Amazon's "x-ray" feature for Kindle books](https://en.wikipedia.org/wiki/X-Ray_(Amazon_Kindle)).

```{r eval=TRUE, fig.width=8, fig.height=3}
textplot_xray(kwic(data_corpus_inaugural[40:57], "american"))
```

You can also pass multiple kwic objects to `plot` to compare the dispersion of different terms:
```{r eval=TRUE, fig.width=8, fig.height=4}
textplot_xray(
     kwic(data_corpus_inaugural[40:57], "american"),
     kwic(data_corpus_inaugural[40:57], "people"),
     kwic(data_corpus_inaugural[40:57], "communist")
)
```

If you're only plotting a single document, but with multiple keywords, then the keywords are displayed one below the other rather than side-by-side.

```{r eval=TRUE, fig.width=8, fig.height=1.5}
mobydickCorpus <- corpus(data_char_mobydick)

textplot_xray(
    kwic(data_char_mobydick, "whale"),
    kwic(data_char_mobydick, "ahab")
)
```

You might also have noticed that the x-axis scale is the absolute token index for single texts and relative token index when multiple texts are being compared. If you prefer, you can specify that you want an absolute scale:

```{r eval=TRUE, fig.width=8, fig.height=4}
textplot_xray(
     kwic(data_corpus_inaugural[40:57], "american"),
     kwic(data_corpus_inaugural[40:57], "people"),
     kwic(data_corpus_inaugural[40:57], "communist"),
     scale = 'absolute'
)
```

In this case, the texts may not have the same length, so the tokens that don't exist in a particular text are shaded in grey.

## Modifying lexical dispersion plots

The object returned is a ggplot object, which can be modified using ggplot:

```{r eval=TRUE, fig.width=8, fig.height=4}
library(ggplot2)
theme_set(theme_bw())
g <- textplot_xray(
     kwic(data_corpus_inaugural[40:57], "american"),
     kwic(data_corpus_inaugural[40:57], "people"),
     kwic(data_corpus_inaugural[40:57], "communist")
)
g + aes(color = keyword) + scale_color_manual(values = c('blue', 'red', 'green'))

```


# 3. Frequency plots


You can plot the frequency of the top features in a text using `topfeatures`.

```{r eval=TRUE, fig.width=8, fig.height=4}
inaugFeatures <- topfeatures(inaugDfm, 100)

# Create a data.frame for ggplot
topDf <- data.frame(
    list(
        term = names(inaugFeatures),
        frequency = unname(inaugFeatures)
    )
)

# Sort by reverse frequency order
topDf$term <- with(topDf, reorder(term, -frequency))

ggplot(topDf) + geom_point(aes(x=term, y=frequency)) +
    theme(axis.text.x=element_text(angle=90, hjust=1))
```

If you wanted to compare the frequency of a single term across different texts, you could plot the dfm matrix like this:

```{r eval=TRUE, fig.width=8, fig.height=4}

americanFreq <- data.frame(list(
    document = rownames(inaugDfm[, 'american']),
    frequency = unname(as.matrix(inaugDfm[, 'american']))
))

ggplot(americanFreq) + geom_point(aes(x=document,y=frequency)) +
    theme(axis.text.x = element_text(angle=90, hjust=1))

```

The above plots are raw frequency plots. For relative frequency plots, (word count divided by the length of the chapter) we can weight the document-frequency matrix. To obtain expected word frequency per 100 words, we multiply by 100. 

```{r eval=TRUE}
relDfm <- weight(inaugDfm, type='relFreq') * 100
head(relDfm)

relFreq <- data.frame(list(
    document = rownames(inaugDfm[, 'american']),
    frequency = unname(as.matrix(relDfm[, 'american']))
))

ggplot(relFreq) + geom_point(aes(x=document,y=frequency)) +
    theme(axis.text.x = element_text(angle=90, hjust=1))
```
